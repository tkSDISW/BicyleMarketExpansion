{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ef785c9-a1c0-4ad7-a185-02a1569ca072",
   "metadata": {},
   "source": [
    "# Model Based System Engineering Assistant: \n",
    "## Leveraging AI for System Engineering models \n",
    "\n",
    "Welcome to the **MBSE Assistant Notebook**, a powerful tool designed to augment your ability to review, comprehend, and enhance system models with AI-driven support. This notebook integrates a variety of capabilities to assist with:\n",
    "\n",
    "1. **Model Review and Comprehension**:\n",
    "   - Gain deeper insights into the structure and behavior of your system model.\n",
    "   - Use AI to clarify relationships, dependencies, and interactions within the model.\n",
    "\n",
    "2. **Impact Analysis**:\n",
    "   - Explore the potential effects of component failures on the system.\n",
    "   - Simulate scenarios to identify vulnerabilities and design improvements.\n",
    "\n",
    "3. **Simulation Generation**:\n",
    "   - Automatically generate simulations based on the model's architecture and behaviors.\n",
    "   - Use simulations for validation, testing, and demonstration purposes.\n",
    "\n",
    "4. **Failure Analysis**:\n",
    "   - Assess the system's resilience under various failure conditions.\n",
    "   - Extract meaningful insights to strengthen reliability and performance.\n",
    "\n",
    "5. **Content Extraction for Downstream Domains**:\n",
    "   - Convert model data into formats suitable for use in other engineering domains.\n",
    "   - Facilitate seamless collaboration across teams and tools.\n",
    "\n",
    "This notebook serves as a comprehensive platform to bridge the gap between system models and actionable insights, empowering architects to make informed decisions and design robust solutions. Whether you're investigating enhancements, running failure simulations, or preparing data for external domains, this assistant streamlines the process with AI-enhanced guidance.\n",
    "\n",
    "Feel free to explore and adapt the prompts and models to suit your specific use case. Let’s dive in and unlock the potential of your system model!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5acc178-1a94-4014-b1f7-13c97a9ba4ec",
   "metadata": {},
   "source": [
    "### Model-Specific Code (Do Not Modify)\n",
    "\n",
    "This section contains code that is specific to the system model. It is updated only when the model is changed and should not require user modifications under normal circumstances.\n",
    "\n",
    "If a new model is introduced, ensure this section is reviewed and updated as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7ba8743-5dac-41be-9083-d44aa0199411",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File '../Bicycle Market Expansion.traceability' does not exist.\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade git+https://github.com/tkSDISW/Capella_Tools \n",
    "import capellambse.decl\n",
    "\n",
    "from capella_tools import capellambse_helper\n",
    "\n",
    "from IPython import display as diag_display\n",
    "resources = {\n",
    "    \"BicycleMarketExpansion\": \"BicycleMarketExpansion/Bicycle Market Expansion\",\n",
    "}\n",
    "path_to_model = \"../Bicycle Market Expansion.aird\"\n",
    "model = capellambse.MelodyModel(path_to_model, resources=resources)\n",
    "from capella_tools import Pub4C\n",
    "# Instantiate the class with the traceability file\n",
    "traceability_store = Pub4C.Traceability_Store(\"../Bicycle Market Expansion.traceability\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f73131d-3ba3-4c6f-8418-378d418156a6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98e07f65-caa7-4e20-9268-7c5df4783e36",
   "metadata": {},
   "source": [
    "## 🔄 Embedding Generation Process\n",
    "\n",
    "### Overview\n",
    "This section generates embeddings, which streamlines processing and analyzing the model. The embeddings provide a structured representation of the data that powers subsequent tasks and visualizations.\n",
    "\n",
    "### When is this step necessary?\n",
    "- **Initial Run:** If this notebook is being run for the first time, embeddings will need to be generated.\n",
    "- **Model Updates:** If the underlying model has been modified, regenerating embeddings ensures the data remains accurate and up-to-date.\n",
    "\n",
    "### Important Notes\n",
    "- **Duration:** This process may take **a minute or more** to complete, depending on the size and complexity of the model.\n",
    "- **Output:** Upon completion, embeddings will be ready for use in subsequent sections of the notebook.\n",
    "\n",
    "### Instructions\n",
    "1. Ensure the required model is loaded.\n",
    "2. Run the cell below to initiate the embedding generation process.\n",
    "3. Wait for the process to complete before proceeding.\n",
    "\n",
    "> 💡 **Tip:** You can monitor progress in the notebook's output cell. If any errors occur, check that the model is properly configured and accessible.\n",
    "\n",
    "---\n",
    "\n",
    "> ⚠️ **Warning:** Interrupting this step may result in incomplete or invalid embeddings. If interrupted, re-run the cell to restart the process.\n",
    "\n",
    "---\n",
    "\n",
    "Continue to the next cell to generate embeddings. 🚀\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c54cb77-76e8-4309-90e0-7da1d2a2d9f8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key retrieved successfully.\n",
      "Loading embeddings\n",
      "embeddings loaded.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from capella_tools  import capella_embeddings_manager\n",
    "\n",
    "# Generate embeddings for all objects\n",
    "model_embedding_manager = capella_embeddings_manager.EmbeddingManager()\n",
    "\n",
    "embedding_file = \"embeddings.json\" \n",
    "model_embedding_manager.set_files( path_to_model , embedding_file)\n",
    "\n",
    "model_embedding_manager.create_model_embeddings(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f671a45d-5335-463c-802a-156296f21ad4",
   "metadata": {},
   "source": [
    "## 🎯 Prompt for System Model Element Analysis\n",
    "\n",
    "### Purpose\n",
    "This cell accepts a prompt to identify and isolate the specific object(s) to be analyzed. Providing detailed and accurate information in the prompt will ensure the best performance during the analysis.\n",
    "\n",
    "### What to Include in Your Prompt\n",
    "For optimal results, specify the following details about the object(s):\n",
    "1. **Type of ARCADIA Object:** Clearly state the type of the object (e.g., Logical Component, Physical Component, Functional Exchange).\n",
    "2. **Name of the Object:** Provide the exact name of the object as defined in the model.\n",
    "3. **ARCADIA Phase:** Specify the phase associated with the object (e.g., Operational Analysis, System Analysis, Logical Architecture, Physical Architecture).\n",
    "4. **Related Objects:** Identify any objects connected via exchanges or dependencies.\n",
    "\n",
    "### Example Prompt\n",
    "Locate the Logical Component named Brake Pedal in the Logical phase and has a Driver supplying input.\n",
    "### ✅ Tips for Success\n",
    "- **Use precise terminology:** Ensure your prompt aligns with the model's structure and terminology.\n",
    "- **Include related objects:** Whenever possible, specify related objects to enhance context and improve analysis accuracy.\n",
    "- **Double-check details:** Verify object names and phases to ensure they match the model exactly.\n",
    "'''\n",
    "\n",
    "### 🚀 Next Steps\n",
    "1. Run the cell below.\n",
    "2. Enter your prompt, providing the necessary details as outlined above.\n",
    "3. Wait for the analysis to complete.\n",
    "4. Select the best index or indexes for analysis. (The last selection will drive selection of a prompt.)\n",
    "\n",
    "> 💡 **Tip:** If you're unsure about the model structure, review the documentation or refer to the model's diagrams for additional guidance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31298768-f6da-4f27-9c76-50d02b7a0fe7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m selected_objects \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_embedding_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_and_select_top_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOCB Cruise Ebike diagram\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/capella_tools/capella_embeddings_manager.py:464\u001b[0m, in \u001b[0;36mEmbeddingManager.query_and_select_top_objects\u001b[0;34m(self, prompt, top_n)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;124;03mQuery and return top N ranked objects based on similarity.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;124;03m:return: List of top N selected objects.\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# Step 1: Rank objects based on the query\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m ranked_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_similar_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;66;03m# Step 2: Display ranked objects\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThis is a list of ranked Objects Based on Query:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/capella_tools/capella_embeddings_manager.py:272\u001b[0m, in \u001b[0;36mEmbeddingManager.find_similar_objects\u001b[0;34m(self, query, top_n)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_similar_objects\u001b[39m(\u001b[38;5;28mself\u001b[39m, query,  top_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m--> 272\u001b[0m     query_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39membedding\n\u001b[1;32m    273\u001b[0m     similarities \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/embeddings.py:128\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    122\u001b[0m             embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[1;32m    123\u001b[0m                 base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m             )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1241\u001b[0m     )\n\u001b[0;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py:919\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 919\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py:1008\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1007\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1008\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py:1057\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py:1008\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1007\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1008\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py:1057\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py:1023\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1022\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1026\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1027\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1031\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1032\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "\n",
    "selected_objects = model_embedding_manager.query_and_select_top_objects(\"OCB Cruise Ebike diagram\", top_n=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd4a6ad-39a9-4bc3-ae26-5d97c5fe394b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## 📝 Generate Structured Input File \n",
    "\n",
    "### Purpose\n",
    "This cell generates a structured structured input file, `capella_model.yaml`, which serves as input for prompts tailored to the object type of the last selected item. This ensures that the prompt aligns with the model's structure and provides accurate context for analysis.\n",
    "\n",
    "### What This Cell Does\n",
    "- Extracts data related to the elements selected.\n",
    "- Structures the data into a YAML format.\n",
    "- Saves the YAML file as `capella_model.yaml` for further use.\n",
    "\n",
    "### Key Features\n",
    "- The YAML file includes:\n",
    "  - **Object Type:** The type of the element.\n",
    "  - **Object Details:** Attributes, relationships, and associated exchanges.\n",
    "  - **Structured Input:** Designed to enhance prompt accuracy and model analysis.\n",
    "\n",
    "### Instructions\n",
    "1. Run this cell to create the `capella_model.yaml` file.\n",
    "2. Ensure the last selected item is correctly identified to avoid mismatched data.\n",
    "3. Use the generated YAML file as structured input for tailored prompts in subsequent steps.\n",
    "\n",
    "### Notes\n",
    "- The file will be saved in the current working directory.\n",
    "- If the selected object changes, re-run this cell to update the YAML file.\n",
    "\n",
    "> 💡 **Tip:** Review the contents of `capella_model.yaml` if needed to ensure accuracy and completeness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db8d5ea-0e49-4098-aedc-0914d956f286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Workflow\n",
    "from capella_tools import capellambse_yaml_manager\n",
    "yaml_handler = capellambse_yaml_manager.CapellaYAMLHandler()\n",
    "   \n",
    "#Generate YAML for the logical component and append to the file\n",
    "for object in  selected_objects : \n",
    "    if object[\"type\"] == \"Diagram\" :\n",
    "        yaml_handler.generate_yaml(model.by_uuid(object[\"uuid\"]))  \n",
    "    else:\n",
    "        yaml_handler.generate_yaml( model.search(object[\"type\"]).by_uuid(object[\"uuid\"]))\n",
    "\n",
    "\n",
    "yaml_handler.generate_traceability_related_objects(model,traceability_store)\n",
    "\n",
    "#yaml_handler.display()\n",
    "yaml_handler.generate_yaml_referenced_objects()\n",
    "#yaml_handler.display()\n",
    "\n",
    "yaml_handler.write_output_file()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1113cb97-36e1-46b4-aec7-9713aea09a64",
   "metadata": {},
   "source": [
    "## 🖼️ Generate Contextual Diagram\n",
    "\n",
    "### Purpose\n",
    "This cell generates a **contextual diagram** for the selected object. The diagram visually represents the object's relationships and interactions, providing a clear and comprehensive view of its context within the model.\n",
    "\n",
    "### Supported Object Types\n",
    "This functionality works the following ARCADIA elements, including:\n",
    "- **Functions**\n",
    "- **Activities**\n",
    "- **Components**\n",
    "- **Entities**\n",
    "- **Exchanges and Interactions**\n",
    "- **Physical Links**\n",
    "\n",
    "### What This Cell Does\n",
    "- Identifies the selected object.\n",
    "- Extracts relevant relationships, exchanges, and dependencies.\n",
    "- Creates a contextual diagram based on the object's type and its connections.\n",
    "\n",
    "### Instructions\n",
    "1. Ensure the object is correctly selected in the previous step.\n",
    "2. Run this cell to generate the contextual diagram.\n",
    "3. Review the output to verify accuracy and completeness.\n",
    "\n",
    "### Key Benefits\n",
    "- **Clarity:** Visualizes how the selected object interacts with other model elements.\n",
    "- **Versatility:** Works seamlessly across ARCADIA functions, activities, components, and entities.\n",
    "- **Actionable Insight:** Helps identify key dependencies and relationships for analysis.\n",
    "\n",
    "### Notes\n",
    "- The diagram will be displayed below upon completion.\n",
    "- If the selected object changes, re-run this cell to update the contextual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6679d117-2c29-4dc1-9eac-b14e602b1cee",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for object in  selected_objects : \n",
    "    #print(object)\n",
    "    if object[\"type\"] == \"Diagram\" :\n",
    "        diagram = model.by_uuid(object[\"uuid\"])\n",
    "        #display(diagram)\n",
    "    else:\n",
    "        obj = model.search(object[\"type\"]).by_uuid(object[\"uuid\"])\n",
    "        capellambse_helper.display_context_diagram(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ed6cc0-6c32-4f80-8a39-1dccfaca5eb5",
   "metadata": {},
   "source": [
    "## 💬 Predefined Prompts for Analysis\n",
    "\n",
    "### Purpose\n",
    "This cell contains predefined prompts for analyzing different types of ARCADIA elements, including components, functions, operational processes, and a default prompt. You can use these as-is or tailor them to suit your specific needs.\n",
    "\n",
    "\n",
    "### Instructions\n",
    "1. The appropriate prompt will be used for your analysis needs.\n",
    "2. Modify the prompt to include additional details or requirements, if necessary.\n",
    "\n",
    "### Notes\n",
    "- Predefined prompts are designed to guide analysis and ensure consistency.\n",
    "- Tailoring the prompts allows you to focus on specific aspects of the model relevant to your use case.\n",
    "\n",
    "> 💡 **Tip:** Save your tailored prompts for reuse in similar analyses or workflows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24590371-907b-4e64-898f-99c5e9499460",
   "metadata": {},
   "outputs": [],
   "source": [
    "component_prompt = \"\"\"\n",
    "Please analyze the yaml file and display the result as .html and specifically provide insights on:\n",
    "1. The purpose of the component.\n",
    "2. Any components that make it up.\n",
    "3. A list of allocated functions and their potential roles.\n",
    "4. How the ports relate to the functions.\n",
    "5. Any traceabilty artifacts linked to the component and the artifacts url.\n",
    "6. Suggestions for improving the component description.\n",
    "7. Create a tabular table with columns for the component and its ports and the port interfaces, the interface souce and the interface target.\n",
    "8. List any property values and the related model element.\n",
    "9. A summary of any related state machines.\n",
    "\"\"\"\n",
    "function_prompt = \"\"\"\n",
    "Please analyze the yaml file and display the result as .html specifically provide insights on:\n",
    "1. The purpose of the function.\n",
    "2. Its owning component.\n",
    "4. Any ports relate to the functions.\n",
    "5. Any traceabilty artifacts linked to the component and the artifacts url.\n",
    "6. Suggestions for improving the function description.\n",
    "7. Create a tabular table with columns for the owning component, this function, its ports and the functional exchanges.\n",
    "\"\"\"\n",
    "activity_prompt = \"\"\"\n",
    "Please analyze the yaml file and display the result as .html specifically provide insights on:\n",
    "1. The purpose of the activity.\n",
    "2. Its actor or entiry.\n",
    "4. Any traceabilty artifacts linked to the component and the artifacts url.\n",
    "7. Suggestions for improving the activity description.\n",
    "7. Create a tabular table with columns for the owning entity or actor, this activity, its exchanges.\n",
    "\"\"\"\n",
    "functional_chain_prompt = \"\"\"\n",
    "Please analyze the YAML file and display the result as .html specifically provide insights on:\n",
    "1. The purpose of the functional chain.\n",
    "2. A table with first column being the owning component, the second being a function, last column being involved functional exchange, organized by involved functional exchanges.\n",
    "3. Any traceabilty artifacts linked to functional chain, functions, owning component and the traceability artifacts url.\n",
    "4. List any property values and the related model element.\n",
    "Please format the analysis in .html suitable for Juypter Notbook display operation.\n",
    "\"\"\"\n",
    "operational_process_prompt = \"\"\"\n",
    "Please analyze the YAML file and display the result as .html specifically provide insights on:\n",
    "1. The purpose of the operation process.\n",
    "2. A table with first column being the owning component, the second being a activities, last column being involved activity exchange, organized by involved activity exchanges.\n",
    "3. Any traceabilty artifacts linked to the operational process chain, activities, owning component and the traceability artifacts url.\n",
    "4. List any property values and the related model element.\n",
    "Please format the analysis in .html suitable for Juypter Notbook display operation.\n",
    "\"\"\"\n",
    "diagram_prompt = \"\"\"\n",
    "Please analyze the YAML file and display the result as .html specifically provide insights on:\n",
    "1. The purpose of the diagram based on its related nodes.\n",
    "2. Describe what the nodes represent in the ARCADIA method and what the diagram is describing.\n",
    "Please format the analysis in .html suitable for Juypter Notbook display operation.\n",
    "\"\"\"\n",
    "default_prompt = \"\"\"\n",
    "Please analyze the YAML file and display the result as .html specifically provide insights on:\n",
    "1. The purpose of the primary component listed first in the yaml file.=.\n",
    "2. List any property values and the related model element.\n",
    "Please format the analysis in .html suitable for Juypter Notbook display operation.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3e82f3-a07b-404e-a230-7ebcf690e3e4",
   "metadata": {},
   "source": [
    "## ⚙️ Execute Default Prompts\n",
    "\n",
    "### Purpose\n",
    "This cell executes the **default prompts** defined for analyzing the model. These prompts are designed to provide general insights and overviews when specific object types or contexts are not explicitly defined.\n",
    "\n",
    "### What This Cell Does\n",
    "- Reads the structured input file (e.g., `capella_model.yaml`).\n",
    "- Uses the default prompts to query key details about the selected object(s).\n",
    "- Outputs the results directly in the notebook.\n",
    "\n",
    "### 🛠️ Instructions\n",
    "1. Ensure the `capella_model.yaml` file is generated and up-to-date.\n",
    "2. Run this cell to execute the default prompts.\n",
    "3. Review the output to verify the accuracy and relevance of the analysis.\n",
    "\n",
    "### 📝 Notes\n",
    "- The default prompts are **general-purpose** and may not capture all details specific to certain object types.\n",
    "- For more tailored analysis, consider using prompts designed for specific ARCADIA elements.\n",
    "\n",
    "> 💡 **Tip:** Use the default prompts as a starting point, then refine or modify them based on your analysis needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf53953-bfae-4677-9f45-906e72aa93e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "#from capella_tools  import Open_AI_RAG_manager\n",
    "\n",
    "from capella_tools import Open_AI_RAG_manager\n",
    "#print(object)\n",
    "if object[\"type\"] ==  \"LogicalComponent\" or object[\"type\"] ==  \"SystemComponent\" or object[\"type\"] ==  \"PhysicalComponent\"  :\n",
    "    prompt = component_prompt\n",
    "elif object[\"type\"] ==  \"FunctionalChain\" :  \n",
    "    prompt = functional_chain_prompt\n",
    "elif object[\"type\"] ==  \"OperationalProcess\":  \n",
    "    prompt = functional_chain_prompt\n",
    "elif object[\"type\"] ==  \"SystemFuntion\" or object[\"type\"] ==  \"LogicalFunction\" or object[\"type\"] ==  \"PhysicalFunction\":\n",
    "    prompt = function_prompt\n",
    "elif object[\"type\"] ==  \"OperationalActivity\" : \n",
    "    prompt = activity_prompt\n",
    "elif object[\"type\"] ==  \"Diagram\" : \n",
    "    prompt = diagram_prompt\n",
    "else :\n",
    "    prompt = default_prompt    \n",
    "# Display Prompt\n",
    "display(Markdown(f\"# The architecture is analyzed by ChatGPT with following prompt.\\n {prompt}\\n\"))\n",
    "\n",
    "# Step 1: Get YAML content\n",
    "yaml_content = yaml_handler.get_yaml_content()\n",
    "\n",
    "# Step 2: Invoke ChatGPT for analysis\n",
    "analyzer = Open_AI_RAG_manager.ChatGPTAnalyzer(yaml_content)\n",
    "analyzer.initial_prompt(prompt)\n",
    "chatgpt_response = analyzer.get_response()\n",
    "\n",
    "# Step 3: Display the response in the notebook\n",
    "#print(\"ChatGPT Analysis:\\n\")\n",
    "display(Markdown(f\"\\n\\n**ChatGPT Analysis:**\\n\"))\n",
    "#print(chatgpt_response)\n",
    "display(HTML(chatgpt_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab07e0f-6cdb-4b16-9c5b-0acd3e7944cd",
   "metadata": {},
   "source": [
    "## ⚙️ Execute Followup Prompts\n",
    "\n",
    "### Purpose\n",
    "This cell executes the **follow up prompts** defined for analyzing the model. These prompts can be added by the note book user in addition to the default prompts\n",
    "\n",
    "### What This Cell Does\n",
    "- Use the structured input file (e.g., `capella_model.yaml`).\n",
    "- Excutes the prompt defined in the cell.\n",
    "- Outputs the results directly in the notebook.\n",
    "\n",
    "### 🛠️ Instructions\n",
    "1. Ensure the `capella_model.yaml` file is generated and up-to-date.\n",
    "2. Run this cell to execute the default prompts.\n",
    "3. Review the output to verify the accuracy and relevance of the analysis.\n",
    "\n",
    "> 💡 **Tip:** Modify the promt to your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab94bcf-5ea3-4d7d-89e8-508dcd603d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Please create a set of 20 business requirements for AMCE Bicycles based on the its Involved Operation Capabilities noted on the {OCB_ Cruiser Ebike diagram. \n",
    "Format the requirement in the following way:\n",
    "1. Each requirement will have a heading and body.\n",
    "2. The heading should be limited to 5 words.\n",
    "3. The body should be written as a shall statement.\n",
    "4. The body to be clear, concise and testable.\n",
    "\"\"\"\n",
    "display(Markdown(f\"\\n\\n**Prompt:**\\n{prompt}\"))\n",
    "analyzer.follow_up_prompt(prompt)\n",
    "chatgpt_response = analyzer.get_response()\n",
    "\n",
    "# Step 3: Display the response in the notebook\n",
    "#print(\"ChatGPT Analysis:\\n\")\n",
    "display(Markdown(f\"\\n\\n**ChatGPT Analysis:**\\n\"))\n",
    "#print(chatgpt_response)\n",
    "display(HTML(chatgpt_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f3bb3e-8db9-49f8-aa73-f050e48091b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Our current operation capabilities and processes is based on mountain bikes, highlight the changes that will have to be made to company to go after your recommendation..\"\n",
    "display(Markdown(f\"\\n\\n**Prompt:**\\n{prompt}\"))\n",
    "analyzer.follow_up_prompt(prompt)\n",
    "chatgpt_response = analyzer.get_response()\n",
    "\n",
    "# Step 3: Display the response in the notebook\n",
    "#print(\"ChatGPT Analysis:\\n\")\n",
    "display(Markdown(f\"\\n\\n**ChatGPT Analysis:**\\n\"))\n",
    "#print(chatgpt_response)\n",
    "display(HTML(chatgpt_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614ada9b-367c-4929-badf-e27c7170b825",
   "metadata": {},
   "source": [
    "## 💬 Launch Interactive Chat on Structured Input\n",
    "\n",
    "### Purpose\n",
    "This cell launches an interactive chat session based on the structured input file, leveraging ARCADIA and Polarion terminology to ensure the analysis remains consistent with the modeling context.\n",
    "\n",
    "### Key Features\n",
    "- Uses the generated structured input file (e.g., `capella_model.yaml`) to guide the conversation.\n",
    "- Supports ARCADIA terms such as **functions**, **components**, **activities**, and **exchanges**.\n",
    "- Incorporates Polarion terms like **workitem**, **requirement**, and **traceability** for seamless integration with requirements management workflows.\n",
    "\n",
    "### How It Works\n",
    "1. The structured input file provides context for the chat session.\n",
    "2. You can interactively query details about the model elements, relationships, and dependencies.\n",
    "3. Responses are tailored using ARCADIA and Polarion terminology.\n",
    "\n",
    "### Example Prompts\n",
    "- **For ARCADIA:**\n",
    "  ```plaintext\n",
    "  What are the dependencies and exchanges for the selected function in the Logical Architecture phase?\n",
    "\n",
    "- **For Polarion:**\n",
    "  ```plaintext\n",
    "  Provide the traceability matrix for the workitem linked to this component.\n",
    "  ```\n",
    "### 🛠️ Instructions\n",
    "1. Ensure the `capella_model.yaml` file has been generated and is up-to-date.\n",
    "2. Run this cell to start the interactive chat session.\n",
    "3. Enter your queries using **ARCADIA** or **Polarion** terms for accurate and relevant responses.\n",
    "\n",
    "### 📝 Notes\n",
    "- The interactive chat dynamically adapts to the content in the structured input file.\n",
    "- Use precise and contextual queries to ensure the best results and insights.\n",
    "\n",
    "> 💡 **Tip:** If you're unfamiliar with ARCADIA or Polarion terminology, consult the respective documentation or glossary for guidance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1d370a-fcf4-4084-9064-f5e11a03a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.interactive_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dea895-123c-4c7f-b386-89510fcfcd9d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb2484d-c283-416d-b5ae-03289fc2a8a1",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c59542-ddf7-4047-9007-2613a7f96589",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edddd2fe-aeef-43a8-94d2-4b7cac1ce700",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
